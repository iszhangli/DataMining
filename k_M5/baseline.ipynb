{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "united-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import cycle\n",
    "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hundred-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'C:/ZhangLI/Codes/DataSet/m5-forecasting-accuracy'\n",
    "calendar = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\n",
    "selling_prices = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')\n",
    "sample_submission = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\n",
    "sales_train_val = pd.read_csv(f'{INPUT_DIR}/sales_train_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "desirable-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / val\n",
    "ids = sorted(list(set(sales_train_val['id'])))  # all items\n",
    "d_cols = [c for c in sales_train_val.columns if 'd_' in c]  # how many sale in every day\n",
    "train_dataset = sales_train_val[d_cols[-100:-30]]\n",
    "val_dataset = sales_train_val[d_cols[-30:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "portable-boring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, ..., 2, 1, 2], dtype=int64)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset\n",
    "predictions = []\n",
    "predictions.append(train_dataset[train_dataset.columns[-1]].values)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "accurate-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1       , 1.11896552, 1.12616995, ..., 1.08170268, 0.8302437 ,\n",
       "        1.07454984],\n",
       "       [0.26666667, 0.25402299, 0.25517241, ..., 0.46434573, 0.63462527,\n",
       "        0.64092484],\n",
       "       [0.46666667, 0.47471264, 0.48534483, ..., 0.37516289, 0.45774927,\n",
       "        0.70847773],\n",
       "       ...,\n",
       "       [1.2       , 1.22068966, 1.24802956, ..., 0.8926793 , 1.05531002,\n",
       "        1.5543564 ],\n",
       "       [0.96666667, 0.98333333, 1.00535714, ..., 1.17753957, 1.01365493,\n",
       "        1.0134195 ],\n",
       "       [1.83333333, 1.86494253, 1.88885468, ..., 2.66855553, 2.2637599 ,\n",
       "        2.017833  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving average  \n",
    "# 正儿八经的滑动平均\n",
    "predictions = []\n",
    "for i in range(len(val_dataset.columns)):\n",
    "    if i == 0:\n",
    "        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n",
    "    if i < 31 and i > 0:\n",
    "        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n",
    "                                  np.mean(predictions[:i], axis=0)))  # This is imp code\n",
    "    if i > 31:\n",
    "        predictions.append(np.mean([predictions[:i]], axis=1))\n",
    "np.transpose(np.array([row.tolist() for row in predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cathedral-watershed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13dc936741b24ba482c38ff2594ea64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-a06b8de9cda2>:10: FutureWarning: the 'smoothing_slope'' keyword is deprecated, use 'smoothing_trend' instead\n",
      "  fit = Holt(row).fit(smoothing_level = 0.3, smoothing_slope = 0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25864250829361135"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "from statsmodels.robust import mad\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels\n",
    "from scipy import signal\n",
    "import statsmodels.api as sm\n",
    "\n",
    "predictions = []\n",
    "for row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n",
    "    fit = Holt(row).fit(smoothing_level = 0.3, smoothing_slope = 0.01)\n",
    "    predictions.append(fit.forecast(30))\n",
    "predictions = np.array(predictions).reshape((-1, 30))\n",
    "error_holt = np.linalg.norm(predictions - val_dataset.values[:len(predictions)])/len(predictions[0])\n",
    "error_holt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "expensive-refund",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f33a535b929438cb05a7e558936e9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.2430515872991969"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n",
    "    fit = ExponentialSmoothing(row, seasonal_periods=3).fit()\n",
    "    predictions.append(fit.forecast(30))\n",
    "predictions = np.array(predictions).reshape((-1, 30))\n",
    "error_exponential = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])\n",
    "error_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "arranged-galaxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cc33042faa46e397ef61efc3e56829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\zhangli\\software\\installer\\python38\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n",
    "    fit = sm.tsa.statespace.SARIMAX(row, seasonal_order=(0, 1, 1, 7)).fit()\n",
    "    predictions.append(fit.forecast(30))\n",
    "predictions = np.array(predictions).reshape((-1, 30))\n",
    "error_arima = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "liberal-genre",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-8934aae8bb9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"2007-12-\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "from fbprophet import Prophet\n",
    "dates = [\"2007-12-\" + str(i) for i in range(1, 31)]\n",
    "predictions = []\n",
    "for row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n",
    "    df = pd.DataFrame(np.transpose([dates, row]))\n",
    "    df.columns = [\"ds\", \"y\"]\n",
    "    model = Prophet(daily_seasonality=True)\n",
    "    model.fit(df)\n",
    "    future = model.make_future_dataframe(periods=30)\n",
    "    forecast = model.predict(future)[\"yhat\"].loc[30:].values\n",
    "    predictions.append(forecast)\n",
    "predictions = np.array(predictions).reshape((-1, 30))\n",
    "error_prophet = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
