{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weekly-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "experimental-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/ZhangLI/Codes/DataSet/optiver-realized-volatility-prediction/'\n",
    "train = pd.read_csv(data_dir + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elegant-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc wap\n",
    "def calc_wap(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1'])/(df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2'])/(df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()  # time_id之间时间点操作\n",
    "# 计算已实现波动率\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "    \n",
    "# 其他函数\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suitable-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed # parallel computing to save time\n",
    "df = pd.DataFrame()\n",
    "stock_id = 1\n",
    "is_train = True\n",
    "if is_train:\n",
    "    file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "    file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "else:\n",
    "    file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "    file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "\n",
    "# preprocess feature\n",
    "df = pd.read_parquet(file_path_book)\n",
    "df['wap'] = calc_wap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "standing-shirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "      <th>wap</th>\n",
       "      <th>log_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001607</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000785</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001673</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001739</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>1.001032</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001411</td>\n",
       "      <td>1.000623</td>\n",
       "      <td>1.001476</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "      <td>1.000780</td>\n",
       "      <td>-0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001607</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>126</td>\n",
       "      <td>36</td>\n",
       "      <td>1.001411</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001476</td>\n",
       "      <td>1.000623</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1.001115</td>\n",
       "      <td>-0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507527</th>\n",
       "      <td>32767</td>\n",
       "      <td>588</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999060</td>\n",
       "      <td>-0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507528</th>\n",
       "      <td>32767</td>\n",
       "      <td>589</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>-0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507529</th>\n",
       "      <td>32767</td>\n",
       "      <td>591</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>126</td>\n",
       "      <td>226</td>\n",
       "      <td>101</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507530</th>\n",
       "      <td>32767</td>\n",
       "      <td>592</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999011</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507531</th>\n",
       "      <td>32767</td>\n",
       "      <td>593</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>125</td>\n",
       "      <td>225</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1507532 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  \\\n",
       "0              5                  0    1.000754    1.001542    1.000689   \n",
       "1              5                  1    1.000754    1.001673    1.000689   \n",
       "2              5                  2    1.000754    1.001411    1.000623   \n",
       "3              5                  3    1.000754    1.001542    1.000689   \n",
       "4              5                  4    1.000754    1.001476    1.000623   \n",
       "...          ...                ...         ...         ...         ...   \n",
       "1507527    32767                588    0.998911    0.999109    0.998812   \n",
       "1507528    32767                589    0.998911    0.999109    0.998812   \n",
       "1507529    32767                591    0.998911    0.999109    0.998812   \n",
       "1507530    32767                592    0.998911    0.999109    0.998812   \n",
       "1507531    32767                593    0.998911    0.999109    0.998812   \n",
       "\n",
       "         ask_price2  bid_size1  ask_size1  bid_size2  ask_size2       wap  \\\n",
       "0          1.001607          1         25         25        100  1.000785   \n",
       "1          1.001739         26         60         25        100  1.001032   \n",
       "2          1.001476          1         25         25        125  1.000780   \n",
       "3          1.001607        125         25        126         36  1.001411   \n",
       "4          1.001542        100        100         25         25  1.001115   \n",
       "...             ...        ...        ...        ...        ...       ...   \n",
       "1507527    0.999208        126         42        101        100  0.999060   \n",
       "1507528    0.999208        126        126        101        200  0.999010   \n",
       "1507529    0.999208        126        226        101        200  0.998982   \n",
       "1507530    0.999208        226        225        101        100  0.999011   \n",
       "1507531    0.999208        125        225        101        100  0.998982   \n",
       "\n",
       "         log_return  \n",
       "0               NaN  \n",
       "1          0.000247  \n",
       "2         -0.000252  \n",
       "3          0.000630  \n",
       "4         -0.000295  \n",
       "...             ...  \n",
       "1507527   -0.000025  \n",
       "1507528   -0.000050  \n",
       "1507529   -0.000028  \n",
       "1507530    0.000028  \n",
       "1507531   -0.000029  \n",
       "\n",
       "[1507532 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建特征\n",
    "def preprocessor_book(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    #calculate return etc\n",
    "    df['wap'] = calc_wap(df)\n",
    "    df['log_return'] = df.groupby('time_id')['wap'].apply(log_return)\n",
    "    \n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['log_return2'] = df.groupby('time_id')['wap2'].apply(log_return)\n",
    "    \n",
    "    df['wap_balance'] = abs(df['wap'] - df['wap2'])\n",
    "    \n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1'])/2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    #dict for aggregate\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'log_return2':[realized_volatility],\n",
    "        'wap_balance':[np.mean],\n",
    "        'price_spread':[np.mean],\n",
    "        'bid_spread':[np.mean],\n",
    "        'ask_spread':[np.mean],\n",
    "        'volume_imbalance':[np.mean],\n",
    "        'total_volume':[np.mean],\n",
    "        'wap':[np.mean],\n",
    "            }\n",
    "    #####groupby / all seconds\n",
    "    df_feature = pd.DataFrame(df.groupby(['time_id']).agg(create_feature_dict)).reset_index()\n",
    "    \n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns] #time_id is changed to time_id_\n",
    "        \n",
    "    ######groupby / last XX seconds\n",
    "    last_seconds = [300]\n",
    "    \n",
    "    for second in last_seconds:\n",
    "        second = 600 - second\n",
    "    \n",
    "        df_feature_sec = pd.DataFrame(df.query(f'seconds_in_bucket >= {second}').groupby(['time_id']).agg(create_feature_dict)).reset_index()\n",
    "        df_feature_sec.columns = ['_'.join(col) for col in df_feature_sec.columns] #time_id is changed to time_id_\n",
    "     \n",
    "        df_feature_sec = df_feature_sec.add_suffix('_' + str(second))\n",
    "        df_feature = pd.merge(df_feature,df_feature_sec,how='left',left_on='time_id_',right_on=f'time_id__{second}')\n",
    "        df_feature = df_feature.drop([f'time_id__{second}'],axis=1)\n",
    "    \n",
    "    #create row_id\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature\n",
    "def preprocessor_trade(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    \n",
    "    aggregate_dictionary = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "    }\n",
    "    \n",
    "    df_feature = df.groupby('time_id').agg(aggregate_dictionary)\n",
    "    \n",
    "    df_feature = df_feature.reset_index()\n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "    \n",
    "    ######groupby / last XX seconds\n",
    "    last_seconds = [300]\n",
    "    \n",
    "    for second in last_seconds:\n",
    "        second = 600 - second\n",
    "    \n",
    "        df_feature_sec = df.query(f'seconds_in_bucket >= {second}').groupby('time_id').agg(aggregate_dictionary)\n",
    "        df_feature_sec = df_feature_sec.reset_index()\n",
    "        \n",
    "        df_feature_sec.columns = ['_'.join(col) for col in df_feature_sec.columns]\n",
    "        df_feature_sec = df_feature_sec.add_suffix('_' + str(second))\n",
    "        \n",
    "        df_feature = pd.merge(df_feature,df_feature_sec,how='left',left_on='time_id_',right_on=f'time_id__{second}')\n",
    "        df_feature = df_feature.drop([f'time_id__{second}'],axis=1)\n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['trade_time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strange-anxiety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  26,  27,  28,\n",
       "        29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "        42,  43,  44,  46,  47,  48,  50,  51,  52,  53,  55,  56,  58,\n",
       "        59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  72,  73,\n",
       "        74,  75,  76,  77,  78,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "       103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       118, 119, 120, 122, 123, 124, 125, 126], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids = train.stock_id.unique()\n",
    "df_train = preprocessor(list_stock_ids = train_ids, is_train = True)  # build feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
