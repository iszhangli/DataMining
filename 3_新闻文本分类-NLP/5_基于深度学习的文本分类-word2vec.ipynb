{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25de7f4fde0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)  # 这样设置后每次的初始化参数都是固定的\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to fold\n",
    "fold_num = 10\n",
    "data_file = 'E:/Dataset/新闻文本分类/train_set.csv'\n",
    "\n",
    "def all_data2fold(fold_num, num=10000):\n",
    "    fold_data = []\n",
    "    f = pd.read_csv(data_file, sep='\\t', encoding='UTF-8', nrows=20000)\n",
    "\n",
    "    texts = f['text'].tolist()[:num]\n",
    "    labels = f['label'].tolist()[:num]\n",
    "\n",
    "    total = len(labels)\n",
    "    index = list(range(total))\n",
    "\n",
    "    # 随机打乱index [0,1,2,3...] -> [366, 3664, 223...]\n",
    "    np.random.shuffle(index)  \n",
    "    all_texts = []\n",
    "    all_labels = []\n",
    "    # 随机打乱样本\n",
    "    for i in index:\n",
    "        all_texts.append(texts[i])\n",
    "        all_labels.append(labels[i])\n",
    "\n",
    "    # all_texts = texts 顺序不同\n",
    "    label2id = {}\n",
    "    # 统计文本属于第几个label\n",
    "    # {'6': [0,20,32,51,64...], '1':[...], ...}\n",
    "    for i in range(total):\n",
    "        label = str(all_labels[i])\n",
    "        if label not in label2id:\n",
    "            label2id[label] = [i]\n",
    "        else:\n",
    "            label2id[label].append(i)\n",
    "\n",
    "    # [[], [], [], [], [], [], [], [], [], []]\n",
    "    all_index = [[] for _ in range(fold_num)]  # 抽取哪些样本\n",
    "    # 分层抽样\n",
    "    for label, data in label2id.items():\n",
    "        # print(label, len(data))\n",
    "        batch_size = int(len(data) / fold_num)  # ('6':505) => batch_size:505/10=50, other:505-500=5\n",
    "        other = len(data) - batch_size * fold_num\n",
    "        for i in range(fold_num):\n",
    "            cur_batch_size = batch_size + 1 if i < other else batch_size  # [51, 51, 51, 51, 51, 50, 50, 50, 50, 50]\n",
    "            batch_data = [data[i * batch_size + b] for b in range(cur_batch_size)]\n",
    "            all_index[i].extend(batch_data)\n",
    "\n",
    "    # all_index 抽样索引\n",
    "    batch_size = int(total / fold_num)  # \n",
    "    other_texts = []\n",
    "    other_labels = []\n",
    "    other_num = 0\n",
    "    start = 0\n",
    "    for fold in range(fold_num):\n",
    "        num = len(all_index[fold])  \n",
    "        print(num)\n",
    "        texts = [all_texts[i] for i in all_index[fold]]  # 每折的样本\n",
    "        labels = [all_labels[i] for i in all_index[fold]]\n",
    "\n",
    "        if num > batch_size:\n",
    "            fold_texts = texts[:batch_size]\n",
    "            other_texts.extend(texts[batch_size:])\n",
    "            fold_labels = labels[:batch_size]\n",
    "            other_labels.extend(labels[batch_size:])\n",
    "            other_num += num - batch_size\n",
    "        elif num < batch_size:\n",
    "            end = start + batch_size - num\n",
    "            fold_texts = texts + other_texts[start: end]\n",
    "            fold_labels = labels + other_labels[start: end]\n",
    "            start = end\n",
    "        else:\n",
    "            fold_texts = texts\n",
    "            fold_labels = labels\n",
    "\n",
    "        assert batch_size == len(fold_labels)\n",
    "\n",
    "        # shuffle\n",
    "        index = list(range(batch_size))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        shuffle_fold_texts = []\n",
    "        shuffle_fold_labels = []\n",
    "        for i in index:\n",
    "            shuffle_fold_texts.append(fold_texts[i])\n",
    "            shuffle_fold_labels.append(fold_labels[i])\n",
    "\n",
    "        data = {'label': shuffle_fold_labels, 'text': shuffle_fold_texts}\n",
    "        fold_data.append(data)\n",
    "    \n",
    "    logging.info(\"Fold lens %s\", str([len(data['label']) for data in fold_data]))\n",
    "    return fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 22:07:02,405 INFO: Fold lens [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006\n",
      "1005\n",
      "1004\n",
      "1003\n",
      "1002\n",
      "999\n",
      "997\n",
      "997\n",
      "994\n",
      "993\n"
     ]
    }
   ],
   "source": [
    "fold_data = all_data2fold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 22:09:17,176 INFO: Total 9000 docs.\n"
     ]
    }
   ],
   "source": [
    "fold_id = 9\n",
    "\n",
    "train_texts = []\n",
    "for i in range(0, fold_id):\n",
    "    data = fold_data[i]\n",
    "    train_texts.extend(data['text'])\n",
    "    \n",
    "logging.info('Total %d docs.' % len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 22:16:21,209 INFO: Start training...\n",
      "2021-09-05 22:16:25,990 INFO: collecting all words and their counts\n",
      "2021-09-05 22:16:25,991 INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-09-05 22:16:26,812 INFO: collected 5266 word types from a corpus of 8158891 raw words and 9000 sentences\n",
      "2021-09-05 22:16:26,812 INFO: Loading a fresh vocabulary\n",
      "2021-09-05 22:16:26,871 INFO: effective_min_count=5 retains 4323 unique words (82% of original 5266, drops 943)\n",
      "2021-09-05 22:16:26,871 INFO: effective_min_count=5 leaves 8156992 word corpus (99% of original 8158891, drops 1899)\n",
      "2021-09-05 22:16:26,883 INFO: deleting the raw counts dictionary of 5266 items\n",
      "2021-09-05 22:16:26,884 INFO: sample=0.001 downsamples 61 most-common words\n",
      "2021-09-05 22:16:26,884 INFO: downsampling leaves estimated 7041426 word corpus (86.3% of prior 8156992)\n",
      "2021-09-05 22:16:26,894 INFO: estimated required memory for 4323 words and 100 dimensions: 5619900 bytes\n",
      "2021-09-05 22:16:26,895 INFO: resetting layer weights\n",
      "2021-09-05 22:16:26,939 INFO: training model with 8 workers on 4323 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-09-05 22:16:27,947 INFO: EPOCH 1 - PROGRESS: at 51.66% examples, 3637918 words/s, in_qsize 15, out_qsize 0\n",
      "2021-09-05 22:16:28,850 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2021-09-05 22:16:28,853 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2021-09-05 22:16:28,855 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2021-09-05 22:16:28,856 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2021-09-05 22:16:28,857 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2021-09-05 22:16:28,858 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-05 22:16:28,860 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-05 22:16:28,861 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-05 22:16:28,862 INFO: EPOCH - 1 : training on 8158891 raw words (7004179 effective words) took 1.9s, 3654313 effective words/s\n",
      "2021-09-05 22:16:29,866 INFO: EPOCH 2 - PROGRESS: at 50.64% examples, 3572510 words/s, in_qsize 15, out_qsize 0\n",
      "2021-09-05 22:16:30,801 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2021-09-05 22:16:30,802 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2021-09-05 22:16:30,803 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2021-09-05 22:16:30,806 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2021-09-05 22:16:30,807 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2021-09-05 22:16:30,809 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-05 22:16:30,811 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-05 22:16:30,813 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-05 22:16:30,813 INFO: EPOCH - 2 : training on 8158891 raw words (7005064 effective words) took 1.9s, 3594879 effective words/s\n",
      "2021-09-05 22:16:31,818 INFO: EPOCH 3 - PROGRESS: at 50.88% examples, 3587779 words/s, in_qsize 16, out_qsize 4\n",
      "2021-09-05 22:16:32,753 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2021-09-05 22:16:32,754 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2021-09-05 22:16:32,756 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2021-09-05 22:16:32,757 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2021-09-05 22:16:32,759 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2021-09-05 22:16:32,761 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-05 22:16:32,762 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-05 22:16:32,763 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-05 22:16:32,764 INFO: EPOCH - 3 : training on 8158891 raw words (7005564 effective words) took 1.9s, 3598958 effective words/s\n",
      "2021-09-05 22:16:33,780 INFO: EPOCH 4 - PROGRESS: at 48.01% examples, 3340068 words/s, in_qsize 8, out_qsize 7\n",
      "2021-09-05 22:16:34,782 INFO: EPOCH 4 - PROGRESS: at 99.07% examples, 3446138 words/s, in_qsize 9, out_qsize 0\n",
      "2021-09-05 22:16:34,787 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2021-09-05 22:16:34,788 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2021-09-05 22:16:34,789 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2021-09-05 22:16:34,790 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2021-09-05 22:16:34,795 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2021-09-05 22:16:34,796 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-05 22:16:34,797 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-05 22:16:34,798 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-05 22:16:34,798 INFO: EPOCH - 4 : training on 8158891 raw words (7004545 effective words) took 2.0s, 3449250 effective words/s\n",
      "2021-09-05 22:16:35,803 INFO: EPOCH 5 - PROGRESS: at 49.73% examples, 3485457 words/s, in_qsize 15, out_qsize 1\n",
      "2021-09-05 22:16:36,809 INFO: EPOCH 5 - PROGRESS: at 98.30% examples, 3429551 words/s, in_qsize 15, out_qsize 0\n",
      "2021-09-05 22:16:36,830 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2021-09-05 22:16:36,831 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2021-09-05 22:16:36,832 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2021-09-05 22:16:36,834 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2021-09-05 22:16:36,836 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2021-09-05 22:16:36,840 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2021-09-05 22:16:36,841 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-09-05 22:16:36,843 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-09-05 22:16:36,844 INFO: EPOCH - 5 : training on 8158891 raw words (7005562 effective words) took 2.0s, 3430064 effective words/s\n",
      "2021-09-05 22:16:36,845 INFO: training on a 40794455 raw words (35024914 effective words) took 9.9s, 3535972 effective words/s\n",
      "2021-09-05 22:16:36,845 INFO: precomputing L2-norms of word weight vectors\n",
      "2021-09-05 22:16:36,847 INFO: saving Word2Vec object under ./word2vec.bin, separately None\n",
      "2021-09-05 22:16:36,848 INFO: not storing attribute vectors_norm\n",
      "2021-09-05 22:16:36,848 INFO: not storing attribute cum_table\n",
      "2021-09-05 22:16:36,876 INFO: saved ./word2vec.bin\n"
     ]
    }
   ],
   "source": [
    "logging.info('Start training...')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "num_features = 100     # Word vector dimensionality\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "\n",
    "train_texts = list(map(lambda x: list(x.split()), train_texts))\n",
    "model = Word2Vec(train_texts, workers=num_workers, size=num_features)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save model\n",
    "model.save(\"./word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 22:17:05,133 INFO: loading Word2Vec object from ./word2vec.bin\n",
      "2021-09-05 22:17:05,167 INFO: loading wv recursively from ./word2vec.bin.wv.* with mmap=None\n",
      "2021-09-05 22:17:05,168 INFO: setting ignored attribute vectors_norm to None\n",
      "2021-09-05 22:17:05,168 INFO: loading vocabulary recursively from ./word2vec.bin.vocabulary.* with mmap=None\n",
      "2021-09-05 22:17:05,169 INFO: loading trainables recursively from ./word2vec.bin.trainables.* with mmap=None\n",
      "2021-09-05 22:17:05,169 INFO: setting ignored attribute cum_table to None\n",
      "2021-09-05 22:17:05,170 INFO: loaded ./word2vec.bin\n",
      "2021-09-05 22:17:05,179 INFO: storing 4323x100 projection weights into ./word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = Word2Vec.load(\"./word2vec.bin\")\n",
    "\n",
    "# convert format\n",
    "model.wv.save_word2vec_format('./word2vec.txt', binary=False)\n",
    "\n",
    "# 所以要怎么分类呢？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
