{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectors + RidgeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('E:/Dataset/新闻文本分类/train_set.csv', sep='\\t', nrows=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2, 64, ..., 24,  8, 30],\n",
       "       [ 2,  2, 25, ..., 11,  4, 14],\n",
       "       [ 0,  0, 27, ..., 14,  6,  7],\n",
       "       ...,\n",
       "       [ 0,  0, 23, ..., 14,  4, 12],\n",
       "       [ 3,  1, 15, ...,  8,  5,  8],\n",
       "       [ 0,  2,  7, ..., 11,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try bag of word\n",
    "# bag of word进行编码\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10)\n",
    "bag_word = vectorizer.fit_transform(train_df['text'])\n",
    "bag_word.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词袋 + 岭回归进行预测\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rc = RidgeClassifier()\n",
    "rc.fit(bag_word[0:10000], train_df.label[0:10000])\n",
    "result = rc.predict(bag_word[10001:])\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(accuracy_score(train_df.label[10001:], result))\n",
    "print(precision_score(train_df.label[10001:], result, average='micro'))\n",
    "print(recall_score(train_df.label[10001:], result, average='micro'))\n",
    "f1_score(train_df.label[10001:], result, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3056611322264453\n",
      "0.3056611322264453\n",
      "0.3056611322264453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3056611322264453"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF + 岭回归进行预测\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3), max_features=3000)\n",
    "train_test = tfidf.fit_transform(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试多分类\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([-1]*30 + [0]*240 + [1]*30 + [2]*30)\n",
    "y_pred = np.array([-1]*10 + [0]*10 + [1]*10 + \n",
    "                  [-1]*40 + [0]*160 + [1]*40 + \n",
    "                  [-1]*5 + [0]*5 + [1]*20 + [2]*30)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试词袋模型\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'hello hello hello hello',\n",
    "    'didi',\n",
    "    'sun sun',\n",
    "    'moon moon moon',\n",
    "    'ace'\n",
    "]\n",
    "vectorizer = CountVectorizer(max_features=5)\n",
    "words = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.vocabulary_)\n",
    "words.toarray() # 这句话中有几个单词，分别在文章中出现了几次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81818021 0.         0.57496187]\n",
      " [0.57973867 0.81480247 0.        ]]\n",
      "{'didi': 0, 'moon': 2, 'hello': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['didi', 'hello', 'moon']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF测试\n",
    "# wordCount/wordTotal\n",
    "#  文章总数/包含该词的文档数\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'didi didi moon',\n",
    "    'didi hello'\n",
    "]\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "# if not smooth is False  /  idf(t) = log [ n / (df(t) + 1) ])\n",
    "# 文章1：didi: tf-2/3 idf-log(2/2)+1\n",
    "# if smooth is True, then need norm 2  /  idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1\n",
    "# 文章1：didi: tf-2/3 idf-log(3/3)+1\n",
    "\n",
    "# then norm2\n",
    "print(tfidf.fit_transform(corpus).toarray())\n",
    "print(tfidf.vocabulary_)\n",
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81818021, 0.57496187])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# didi\n",
    "import math\n",
    "tf_didi_1 = 2/3 * (np.log(3/3)+1)\n",
    "tf_moon_1 = 1/3 * (np.log(3/2)+1)\n",
    "\n",
    "norm = np.sqrt(tf_didi_1**2 + tf_moon_1**2)\n",
    "\n",
    "[tf_didi_1, tf_moon_1] / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF 常规的的实现方法\n",
    "import numpy as np # 数值计算、矩阵运算、向量运算\n",
    "import pandas as pd # 数值分析、科学计算\n",
    "\n",
    "# 定义文档\n",
    "docA = 'The cat sat on my bed'\n",
    "docB = 'The dog sat on my knees'\n",
    "\n",
    "# 切割文档\n",
    "bowA = docA.split(' ')\n",
    "bowB = docB.split(' ')\n",
    "# bowA # ['The', 'cat', 'sat', 'on', 'my', 'bed']\n",
    "# bowB # ['The', 'dog', 'sat', 'on', 'my', 'knees']\n",
    "\n",
    "# 构建词库\n",
    "wordSet = set(bowA).union(set(bowB))\n",
    "# wordSet # {'The', 'bed', 'cat', 'dog', 'knees', 'my', 'on', 'sat'}\n",
    "\n",
    "# 用字典来保存词出现的次数\n",
    "wordDictA = dict.fromkeys(wordSet, 0)\n",
    "wordDictB = dict.fromkeys(wordSet, 0)\n",
    "\n",
    "# 遍历文档，统计词数\n",
    "# 针对每篇文章，也就是有几个向量\n",
    "for word in bowA:  \n",
    "    wordDictA[word] += 1  # 构建bag of words\n",
    "for word in bowB:\n",
    "    wordDictB[word] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    # 用一个字典对象保存 TF，把所有对应于 bow 文档里的 TF都计算出来\n",
    "    tfDict = {}\n",
    "    nbowCount = len(bow)  # 文章中词的个数\n",
    "    print(nbowCount)\n",
    "\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / nbowCount\n",
    "    return tfDict\n",
    "tfA = computeTF(wordDictA, bowA)\n",
    "tfB = computeTF(wordDictB, bowB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'The': 1, 'dog': 0, 'knees': 0, 'sat': 1, 'cat': 1, 'bed': 1, 'on': 1, 'my': 1}, {'The': 1, 'dog': 1, 'knees': 1, 'sat': 1, 'cat': 0, 'bed': 0, 'on': 1, 'my': 1}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'The': 0.0,\n",
       " 'dog': 0.17609125905568124,\n",
       " 'knees': 0.17609125905568124,\n",
       " 'sat': 0.0,\n",
       " 'cat': 0.17609125905568124,\n",
       " 'bed': 0.17609125905568124,\n",
       " 'on': 0.0,\n",
       " 'my': 0.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeIDF(wordDictList):\n",
    "    print(wordDictList)  # 利用之前构建的bag of words\n",
    "    # 用一个字典对象保存 IDF，每个词作为 key，初始值为 0\n",
    "    idfDict = dict.fromkeys(wordDictList[0], 0)\n",
    "    # 总文档数量\n",
    "    N = len(wordDictList)\n",
    "    import math\n",
    "\n",
    "    for wordDict in wordDictList:  # 统计所有文章中，单词的个数\n",
    "        # 遍历字典中的每个词汇，统计 Ni\n",
    "        for word, count in wordDict.items():\n",
    "            if count > 0 :\n",
    "                # 先把 Ni 增加 1，存入到 idfDict 中\n",
    "                idfDict[word] += count\n",
    "\n",
    "    # 已经得到所有词汇 i 对应的 Ni，现在根据公式把它替换成 idf 值\n",
    "    for word, Ni in idfDict.items():\n",
    "        idfDict[word] = math.log10((N + 1)/(Ni + 1))\n",
    "    return idfDict\n",
    "\n",
    "# 测试\n",
    "idfs = computeIDF([wordDictA, wordDictB])\n",
    "idfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
