【基础问题】
Q1
模型的方差和偏差是什么，怎么减少 bias 和 var
方差与偏差的区别
过拟合和欠拟合
防止过拟合的方法？
样本不平衡的解决办法
数据不平衡问题处理
结构风险和经验风险怎么理解
l1 和 l2 正则化的区别是什么，是什么原因导致的
L1 和 L2 区别
模型过拟合解决方法，为什么提前停止可以解决过拟合问题？
机器学习泛化能力评测指标
生成式模型和判别式模型
常见的特征选择方法
余弦相似度、欧式距离与曼哈顿距离
Q3
归一化和标准化区别
你常用的优化算法？有什么特点？为什么？
模型评价指标都有什么，AUC 是什么，代表什么东西
关于样本不平衡都有什么方法处理
auc 含义公式
Q4
模型有过拟合的现象，过拟合怎么办？
L1 正则和 L2 正则有啥区别？
特征工程怎么做的？
常用评估指标介绍下
Q2
多标签 loss
多标签分类准确率


【降维】
Q1
PCA 是什么？实现过程是什么，意义是什么？
简述 K-means
Q3
knn 算法的思想
knn 的 k 设置的过大会有什么问题
Kmeans 和 EM 算法？Kmeans 和 EM 算法很相似，类比一下？
Q2-4
请介绍 k-mean 算法的原理


【逻辑回归】
Q1
手写交叉熵损失函数
简单介绍一下逻辑回归算法
逻辑回归中参数求解方法
逻辑回归中为什么使用对数损失而不用平方损失
逻辑回归公式推导
逻辑回归的优缺点
LR 和线性回归的区别
特征高度相关对逻辑回归的影响
Q3
逻辑回归损失函数，并推导梯度下降公式
Q2-4
逻辑回归怎么分类非线性数据
逻辑回归引入核方法后损失函数如何求导


【决策树】
Q1
熵、条件熵、互信息、相对熵
ID3、C4.5、CART 树的算法思想
ID3、C4.5、CART 树分裂依据的公式
为什么信息增益比比信息增益好
ID3、C4.5、CART 树的区别
随机森林的大致过程和优缺点
随机森林和 GBDT 区别
Q3
熵，交叉熵的概念
Q2-4
决策树有多少种，分别的损失函数是什么？
决策树的两种剪枝策略分别是什么
信息增益比跟信息增益相比，优势是什么

【GBDT】
Q1
简单介绍一下 XGBoost
XGBoost 与 GBDT 有什么不同
XGBoost 为什么使用泰勒二阶展开
XGBoost 防止过拟合的方法
XGBoost 如何处理缺失值
XGBoost 如何选择最佳分裂点
XGBoost 如何评价特征的重要性
GBDT 与 Xgboost 的区别
XGBoost 和 LightGBM 的区别
XGBoost 模型如果过拟合了怎么解决
bagging、boosting、stacking 的异同