【基础问题】
Q1
* 模型的方差和偏差是什么，怎么减少

  > 对于同一个模型的参数结构一定，参数一定。
  > 交叉验证针对不同的数据集- 如果偏差大，方差小。说明模型还是欠拟合的。
  > 交叉验证针对不同的数据集-如果偏差小，方差大（预测结果的离散程度），说明模型过拟合了。
  > 1-偏差：预测与真实值的偏差，偏差过大因为模型欠拟合
  > 增大数据量，增加模型的复杂度
  > 2-方差：预测结果的离散情况，方差过大因为模型过拟合
  > 减少模型的复杂度，正则化，减少模型的参数，dropout

* 过拟合和欠拟合，防止过拟合的方法

  > 表现：1-过拟合：训练集误差和测试集误差过大。模型复杂度高于实际问题。
  > 2-欠拟合：在训练集上没有获得小的误差。就是模型的复杂度低，模型没有学到数据的规律。
  > 1-过拟合：
  > 数据偏差：1-增大数据集；2-数据增强
  > L1,L2正则化
  > Dropout
  > early stop
  > 2-欠拟合：
  > 增大数据量
  > 增加模型的复杂度

* 模型过拟合解决方法，为什么提前停止可以解决过拟合问题？

  > 在样本不存在偏差的情况下，随着训练的轮数的增加，在测试集上的方差的表现应该是先减小或增加。在方差增加的那个点停止训练。

* l1 和 l2 正则化的区别是什么，是什么原因导致的

  > 1-L1：模型各个参数的绝对值之和
  > 为最优的参数值很大概率出现在坐标轴上，这样就会导致某一维的权重为 0 ，产生稀疏权重矩阵
  > L1 的作用是为了矩阵稀疏化。假设的是模型的参数取值满足拉普拉斯分布
  > 2-L2: 模型各个参数的平方和的开方值
  > 最优的参数值很小概率出现在坐标轴上，因此每一维的参数都不会是 0
  > L2 的作用是为了使模型更平滑，得到更好的泛化能力。假设的是参数是满足高斯分布

* 样本不平衡的解决办法， 数据不平衡问题处理

  > 1-欠采样：从大类中剔除一些
  > 2-过采样：从小类中复制一些
  > 3-数据合成：从少类中创建合成
  > 4-数据增强：对于图片数据
  > 5-增加其他特征


* 生成式模型和判别式模型

  > 1-生成式：p(x/y)p(y) = p(x,y) = p(y/x)p(x) 朴素贝叶斯模型，混合高斯模型，HMM
  > 2-判别式：学习条件概率分布p(y/x) 感知机，决策树，逻辑回归，CRF



* 余弦相似度、欧式距离与曼哈顿距离

  > 1-余弦相似度：向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小 [cos=A*B/(sqrt(A**2)+sqrt(B**2))][-1, 1]
  > 2-欧式距离：两点的长度
  > 3-曼哈顿距离：两点在坐标轴上投影的距离：|x1-x2|+|y1-y2|



Q3
归一化和标准化区别
你常用的优化算法？有什么特点？为什么？
模型评价指标都有什么，AUC 是什么，代表什么东西
关于样本不平衡都有什么方法处理
auc 含义公式

Q4
模型有过拟合的现象，过拟合怎么办？
L1 正则和 L2 正则有啥区别？
特征工程怎么做的？
常用评估指标介绍下
Q2
多标签 loss
多标签分类准确率


【降维】
Q1
PCA 是什么？实现过程是什么，意义是什么？
简述 K-means
Q3
knn 算法的思想
knn 的 k 设置的过大会有什么问题
Kmeans 和 EM 算法？Kmeans 和 EM 算法很相似，类比一下？
Q2-4
请介绍 k-mean 算法的原理


【逻辑回归】
Q1
手写交叉熵损失函数
简单介绍一下逻辑回归算法
逻辑回归中参数求解方法
逻辑回归中为什么使用对数损失而不用平方损失
逻辑回归公式推导
逻辑回归的优缺点
LR 和线性回归的区别
特征高度相关对逻辑回归的影响
Q3
逻辑回归损失函数，并推导梯度下降公式
Q2-4
逻辑回归怎么分类非线性数据
逻辑回归引入核方法后损失函数如何求导


【决策树】
Q1
熵、条件熵、互信息、相对熵
ID3、C4.5、CART 树的算法思想
ID3、C4.5、CART 树分裂依据的公式
为什么信息增益比比信息增益好
ID3、C4.5、CART 树的区别
随机森林的大致过程和优缺点
随机森林和 GBDT 区别
Q3
熵，交叉熵的概念
Q2-4
决策树有多少种，分别的损失函数是什么？
决策树的两种剪枝策略分别是什么
信息增益比跟信息增益相比，优势是什么

【GBDT】
Q1
简单介绍一下 XGBoost
XGBoost 与 GBDT 有什么不同
XGBoost 为什么使用泰勒二阶展开
XGBoost 防止过拟合的方法
XGBoost 如何处理缺失值
XGBoost 如何选择最佳分裂点
XGBoost 如何评价特征的重要性
GBDT 与 Xgboost 的区别
XGBoost 和 LightGBM 的区别
XGBoost 模型如果过拟合了怎么解决
bagging、boosting、stacking 的异同